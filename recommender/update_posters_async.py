"""
Production-Grade Async TMDB Poster Fetcher
Run: python update_posters_async.py

Performance: ~10x faster than sync version
- Sync: ~30-40 minutes for 7000 movies
- Async: ~3-5 minutes for 7000 movies
"""
import asyncio
import aiohttp
import pandas as pd
import time
import re
from datetime import datetime, timedelta

TMDB_API_KEY = '937bdb1c447a5f3d54df1951ba92f033'
CONCURRENT_REQUESTS = 50  # Process 50 movies simultaneously
RATE_LIMIT_PER_SECOND = 40  # TMDB allows 40 req/sec
SAVE_INTERVAL = 100  # Save every 100 movies
MAX_RETRIES = 3

class AsyncPosterFetcher:
    def __init__(self):
        self.semaphore = asyncio.Semaphore(CONCURRENT_REQUESTS)
        self.rate_limiter = asyncio.Semaphore(RATE_LIMIT_PER_SECOND)
        self.session = None
        self.stats = {
            'success': 0,
            'failed': 0,
            'total': 0,
            'start_time': None
        }
    
    def clean_title(self, title):
        return re.sub(r'\s*\(\d{4}\)\s*$', '', str(title)).strip()
    
    async def fetch_poster(self, title, idx):
        """Fetch single poster with retry logic"""
        async with self.semaphore:  # Limit concurrent requests
            for attempt in range(MAX_RETRIES):
                try:
                    async with self.rate_limiter:  # Rate limiting
                        async with self.session.get(
                            'https://api.themoviedb.org/3/search/movie',
                            params={'api_key': TMDB_API_KEY, 'query': self.clean_title(title)},
                            timeout=aiohttp.ClientTimeout(total=5)
                        ) as response:
                            if response.status == 200:
                                data = await response.json()
                                if data.get('results'):
                                    poster_path = data['results'][0].get('poster_path')
                                    if poster_path:
                                        self.stats['success'] += 1
                                        return idx, f"https://image.tmdb.org/t/p/w500{poster_path}"
                            
                            # Rate limit hit
                            if response.status == 429:
                                await asyncio.sleep(1)
                                continue
                    
                    self.stats['failed'] += 1
                    return idx, ''
                    
                except asyncio.TimeoutError:
                    if attempt < MAX_RETRIES - 1:
                        await asyncio.sleep(0.5 * (attempt + 1))  # Exponential backoff
                        continue
                except Exception as e:
                    if attempt < MAX_RETRIES - 1:
                        await asyncio.sleep(0.5 * (attempt + 1))
                        continue
            
            self.stats['failed'] += 1
            return idx, ''
    
    def print_progress(self, processed, total):
        """Print progress with ETA"""
        elapsed = time.time() - self.stats['start_time']
        rate = processed / elapsed if elapsed > 0 else 0
        remaining = total - processed
        eta_seconds = remaining / rate if rate > 0 else 0
        eta = str(timedelta(seconds=int(eta_seconds)))
        
        print(f"\r[{processed}/{total}] "
              f"âœ“ {self.stats['success']} "
              f"âœ— {self.stats['failed']} "
              f"| {rate:.1f} req/s "
              f"| ETA: {eta}", end='', flush=True)
    
    async def fetch_all(self, df, missing_indices):
        """Fetch all posters concurrently"""
        self.stats['start_time'] = time.time()
        self.stats['total'] = len(missing_indices)
        
        connector = aiohttp.TCPConnector(limit=CONCURRENT_REQUESTS, ttl_dns_cache=300)
        async with aiohttp.ClientSession(connector=connector) as session:
            self.session = session
            
            # Create tasks for all missing posters
            tasks = []
            for idx in missing_indices:
                title = df.loc[idx, 'title']
                tasks.append(self.fetch_poster(title, idx))
            
            # Process in batches with progress updates
            results = []
            batch_size = SAVE_INTERVAL
            
            for i in range(0, len(tasks), batch_size):
                batch = tasks[i:i + batch_size]
                batch_results = await asyncio.gather(*batch)
                results.extend(batch_results)
                
                # Update dataframe with batch results
                for idx, poster_url in batch_results:
                    df.at[idx, 'poster_url'] = poster_url
                
                # Save progress
                df.to_csv('movies.csv', index=False)
                self.print_progress(len(results), len(tasks))
            
            print()  # New line after progress
            return results

async def main():
    print("ðŸš€ Async TMDB Poster Fetcher")
    print("=" * 50)
    
    # Load CSV
    print("Loading movies.csv...")
    df = pd.read_csv('movies.csv')
    
    # Add poster_url column if not exists
    if 'poster_url' not in df.columns:
        df['poster_url'] = ''
        print("âœ“ Added poster_url column")
    
    # Find missing posters
    missing_mask = (df['poster_url'] == '') | (df['poster_url'].isna())
    missing_indices = df[missing_mask].index.tolist()
    
    if not missing_indices:
        print("âœ“ All posters already fetched!")
        return
    
    print(f"âœ“ Found {len(missing_indices)} movies without posters")
    print(f"âœ“ Concurrent requests: {CONCURRENT_REQUESTS}")
    print(f"âœ“ Rate limit: {RATE_LIMIT_PER_SECOND} req/s")
    print()
    
    # Fetch posters
    fetcher = AsyncPosterFetcher()
    start_time = time.time()
    
    await fetcher.fetch_all(df, missing_indices)
    
    # Final save
    df.to_csv('movies.csv', index=False)
    
    # Print summary
    elapsed = time.time() - start_time
    print()
    print("=" * 50)
    print(f"âœ… Completed in {elapsed:.1f} seconds ({elapsed/60:.1f} minutes)")
    print(f"âœ“ Success: {fetcher.stats['success']}")
    print(f"âœ— Failed: {fetcher.stats['failed']}")
    print(f"âš¡ Average speed: {len(missing_indices)/elapsed:.1f} req/s")
    print(f"ðŸ’¾ Saved to movies.csv")

if __name__ == '__main__':
    asyncio.run(main())
